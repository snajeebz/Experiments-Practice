{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Polars vs Pandas Processing Time and RAM comparison](https://www.kaggle.com/najeebz/polaris-vs-pandas-performance-comparison)\n## Dataset: [Child Mind Institute - Detect Sleep States](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/overview)\n_______________________________________________________________________ \n# Author Details:\n- Name: Najeeb Haider Zaidi\n- Email: zaidi.nh@gmail.com\n- Profiles: [Github](https://github.com/snajeebz)  [LinkedIn](https://www.linkedin.com/in/najeebz) [Kaggle](https://www.kaggle.com/najeebz)\n- Copyrights 2023-2024 (c) are reserved only by the author: Najeeb Haider Zaidi\n- Opensource; anyone can copy use and reuse the code and results.\n________________________________________________________________________\n# Attributions:\nThe Dataset has been provided by Child Mind Institute. in [Kaggle Competition](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/overview).\n________________________________________________________________________\n# Ways to Access/Execute:\n- [Execute it in Kaggle](https://www.kaggle.com/najeebz/polars-vs-pandas-performance-comparison)\n- [Github Repository for this and other Experimental Evaluations](https://github.com/snajeebz/Experiments-Practice)\n_________________________________________________________________________\n# Objective:\n\n> We need to compare Pandas and Polars, we will run different operations through Pandas and Polars and generate a comparison report of the both at the end.","metadata":{}},{"cell_type":"markdown","source":"# Installing and Importing and Initializing Libraries.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\nimport polars as pl\nfrom datetime import datetime as dt\nfrom tqdm import tqdm\nimport tracemalloc\ntqdm.pandas()\npd.set_option('display.max_row', 500)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_colwidth', None)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-09T10:26:23.425835Z","iopub.execute_input":"2023-12-09T10:26:23.426280Z","iopub.status.idle":"2023-12-09T10:26:24.269531Z","shell.execute_reply.started":"2023-12-09T10:26:23.426244Z","shell.execute_reply":"2023-12-09T10:26:24.268538Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creating a dataframe to store performance statistics","metadata":{}},{"cell_type":"code","source":"dict = {'function':['Reading','Windowing', 'Rolling', 'Merging', 'Clustering','Scaling'],\n        'pandas_mem':[0.0,0,0,0,0,0.0],\n        'pandas_duration':[0.0,0,0,0,0,0.0],\n        'polars_mem': [0.0,0,0,0,0,0.0],\n        'polars_duration':[0.0,0,0,0,0,0.0]\n       }\n\nstats = pd.DataFrame(dict)\nstats\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:26:24.271357Z","iopub.execute_input":"2023-12-09T10:26:24.272151Z","iopub.status.idle":"2023-12-09T10:26:24.311327Z","shell.execute_reply.started":"2023-12-09T10:26:24.272111Z","shell.execute_reply":"2023-12-09T10:26:24.309814Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"     function  pandas_mem  pandas_duration  polars_mem  polars_duration\n0     Reading         0.0              0.0         0.0              0.0\n1   Windowing         0.0              0.0         0.0              0.0\n2     Rolling         0.0              0.0         0.0              0.0\n3     Merging         0.0              0.0         0.0              0.0\n4  Clustering         0.0              0.0         0.0              0.0\n5     Scaling         0.0              0.0         0.0              0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>function</th>\n      <th>pandas_mem</th>\n      <th>pandas_duration</th>\n      <th>polars_mem</th>\n      <th>polars_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Reading</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Windowing</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rolling</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Merging</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clustering</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Scaling</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Functions using Pandas","metadata":{}},{"cell_type":"markdown","source":"# Windowing the training data\n### As the target is to detect an event, \n### So, extracting timesteps before and after the events. ","metadata":{}},{"cell_type":"code","source":"def window(df, win_size):\n    tracemalloc.start()\n    global stats\n    ind=df.index[df['event'].isna()==False]\n    c=0\n    df['window']=np.nan\n    for i in tqdm(ind):\n        a=i-win_size\n        b=i+win_size\n        df['window'].loc[a:i]=int(c)\n        c=c+1\n        df['window'].loc[i:b]=int(c)\n        c=c+1\n    df['window'].dropna(inplace=True)\n    print( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    stats['pandas_mem'][stats['function']=='Windowing']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\n    tracemalloc.stop()\n    return df[df['window'].isna()==False]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:26:24.313360Z","iopub.execute_input":"2023-12-09T10:26:24.313791Z","iopub.status.idle":"2023-12-09T10:26:24.327746Z","shell.execute_reply.started":"2023-12-09T10:26:24.313754Z","shell.execute_reply":"2023-12-09T10:26:24.326294Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Removing the steps where change in anglez is insignificant and enmo is zero (device is supposed not to be worn)","metadata":{}},{"cell_type":"code","source":"def inactive_periods(df):\n    print(\"shape before application: \",df.shape)\n    df['diff_anglez']=df['anglez'].diff()\n    df=df[(df['enmo']!=0.0) | (df['diff_anglez']!=0.0)]\n    print(\"shape after application: \",df.shape)\n    df.drop('diff_anglez', inplace=True, axis=1)\n    print(\"shape after completion: \",df.shape)\n    print(\"removed \")\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:26:24.330891Z","iopub.execute_input":"2023-12-09T10:26:24.331345Z","iopub.status.idle":"2023-12-09T10:26:24.341080Z","shell.execute_reply.started":"2023-12-09T10:26:24.331268Z","shell.execute_reply":"2023-12-09T10:26:24.339472Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Clustering the Enmo and Anglez","metadata":{}},{"cell_type":"code","source":"def clustering(df):\n    tracemalloc.start()\n    global stats\n    from sklearn.cluster import KMeans\n    from sklearn.preprocessing import StandardScaler    \n    X=df[['anglez','enmo']]\n#Scalling the data\n    scaler=StandardScaler()\n    X_scaled=scaler.fit_transform(X)\n#perform clustering\n    model=KMeans(n_clusters=4,algorithm=\"elkan\" )\n    model.fit(X_scaled)\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    stats['pandas_mem'][stats['function']=='Clustering']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\n    tracemalloc.stop()\n    return model.labels_\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:26:24.343427Z","iopub.execute_input":"2023-12-09T10:26:24.344418Z","iopub.status.idle":"2023-12-09T10:26:24.358149Z","shell.execute_reply.started":"2023-12-09T10:26:24.344378Z","shell.execute_reply":"2023-12-09T10:26:24.357016Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Adding Rolling Standard Deviations\n\n- As per observation enmo and anglez varies frequently and more than normal for few timesteps before and after the event.\n- In order to consider the variations into the modelling, using the method.","metadata":{}},{"cell_type":"code","source":" def rollingstd(series_df):\n    tracemalloc.start()\n    global stats\n  # Creating columns with nans\n    series_df['sd_enmo_1']=np.nan    # 1 min rolling std: enmo\n    series_df['sd_anglez_1']=np.nan  # 1 min rolling std: anglez\n    series_df['m_enmo_2']=np.nan     # 2 min rolling mean: enmo\n    series_df['m_anglez_2']=np.nan   # 2 min rolling std: anglez \n    print('anglez rolling std 12')\n    series_df['sd_anglez_1'] = (series_df.groupby('series_id')['anglez']\n                      .rolling(12)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling std 2')\n    series_df['sd_anglez_1'][series_df['sd_anglez_1'].isna()==True] = (series_df.groupby('series_id')['anglez']\n                      .rolling(2)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling std 12')\n    series_df['sd_enmo_1'] = (series_df.groupby('series_id')['enmo']\n                      .rolling(12)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling mean 24')\n    series_df['m_enmo_2'] = (series_df.groupby('series_id')['enmo']\n                      .rolling(24)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling mean 24')\n    series_df['m_anglez_2'] = (series_df.groupby('series_id')['anglez']\n                      .rolling(24)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling std 2')\n    print('Nans in sd_emno_1: ',series_df['sd_enmo_1'].isnull().sum())\n    series_df['sd_enmo_1'][series_df['sd_enmo_1'].isna()==True] = (series_df.groupby('series_id')['enmo']\n                      .rolling(2)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling mean 2')\n    series_df['m_enmo_2'][series_df['m_enmo_2'].isna()==True] = (series_df.groupby('series_id')['enmo']\n                      .rolling(2)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling mean 2')\n    series_df['m_anglez_2'][series_df['m_anglez_2'].isna()==True] = (series_df.groupby('series_id')['anglez']\n                      .rolling(2)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n#Series wise rolling std and mean\n# filling rest of nans\n    print('Nans in sd_emno_1: ',series_df['sd_enmo_1'].isnull().sum())\n    series_df['sd_enmo_1'].fillna(0.0, inplace=True)\n    series_df['sd_anglez_1'].fillna(0.0, inplace=True)\n    series_df['m_enmo_2'].fillna(0.0, inplace=True)\n    series_df['m_anglez_2'].fillna(0.0, inplace=True)\n    print('Nans after removal: ',series_df['sd_enmo_1'].isnull().sum())\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    stats['pandas_mem'][stats['function']=='Rolling']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\n    tracemalloc.stop()\n    return(series_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:26:24.359963Z","iopub.execute_input":"2023-12-09T10:26:24.360412Z","iopub.status.idle":"2023-12-09T10:26:24.382932Z","shell.execute_reply.started":"2023-12-09T10:26:24.360320Z","shell.execute_reply":"2023-12-09T10:26:24.381458Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Scaling the data","metadata":{}},{"cell_type":"code","source":"def scale(X):\n    tracemalloc.start()\n    global stats\n    from sklearn import preprocessing\n    scaler=preprocessing.StandardScaler().fit(X)\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    stats['pandas_mem'][stats['function']=='Scaling']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\n    tracemalloc.stop()\n    return (scaler.transform(X))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:26:24.384792Z","iopub.execute_input":"2023-12-09T10:26:24.385552Z","iopub.status.idle":"2023-12-09T10:26:24.400033Z","shell.execute_reply.started":"2023-12-09T10:26:24.385514Z","shell.execute_reply":"2023-12-09T10:26:24.398910Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Testing Pandas","metadata":{}},{"cell_type":"code","source":"# Importing the datasets\nprint('Importing Training Datasets')\ntnow=dt.now()\ntracemalloc.start()\ndf_series=pd.read_parquet(path=\"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\", engine='auto')\ndf_events=pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\nprint('Datasets Imported...')\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Reading']=dt.now()-tnow\nstats['pandas_mem'][stats['function']=='Reading']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\nprint( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n\ntracemalloc.stop()\nprint('______________________________________')\n\n# Merging the datasets\nprint('Merging the training datasets...')\ntnow=dt.now()\ntracemalloc.start()\nevents=df_events[['series_id', 'step','event']]\nseries_df=pd.merge(df_series,events,on=[\"step\",\"series_id\"],how='left')\ndf_series=[]\ndf_event=[]\nseries_df['sleep']=np.nan\nseries_df.loc[series_df[\"event\"]==\"onset\", \"sleep\"] = 1\nseries_df.loc[series_df[\"event\"]==\"wakeup\", \"sleep\"] = 0\nseries_df['sleep'].fillna(method='ffill', inplace=True)\nseries_df['sleep'].fillna(value=0, inplace=True)\nprint('Datasets Merged...')\nprint('Time Taken: ',dt.now()-tnow)\nprint( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\nstats['pandas_duration'][stats['function']=='Merging']=dt.now()-tnow\nstats['pandas_mem'][stats['function']=='Merging']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\ntracemalloc.stop()\nprint('______________________________________')\n\n# Removing the periods of inactivity\nprint('Removing the periods of Inactivity...')\nseries_df=inactive_periods(series_df)\nprint('______________________________________')\n# Forming Windows\nwin_size=720  #60mins\ntnow=dt.now()\nprint('Creating Windows each size: ',win_size)\nseries_df=window(series_df,win_size)\nprint('Windows formed...')\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Windowing']=dt.now()-tnow\n\nprint('______________________________________')\n\n# Adding the columns of Standard Deviation (1 min)\ntnow=dt.now()\nprint('Adding columns to account for deviation in enmo and anglez 1 min rolling...')\nseries_df=rollingstd(series_df)\nseries_df['sd_anglez_1']=pd.to_numeric(series_df['sd_anglez_1'])\nseries_df['sd_enmo_1']=pd.to_numeric(series_df['sd_enmo_1'])\nseries_df['m_anglez_2']=pd.to_numeric(series_df['m_anglez_2'])\nseries_df['m_enmo_2']=pd.to_numeric(series_df['m_enmo_2'])\nprint('Std columns added...')\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Rolling']=dt.now()-tnow\nprint('______________________________________')\n\n# Clustering the Data\ntnow=dt.now()\nprint('Clustering the data based on enmo and anglez...')\nseries_df['cluster']=(clustering(series_df)+1)/4\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Clustering']=dt.now()-tnow\nprint('Added clusters...')\nprint('______________________________________')\nstats\n# Creating dataframes for training\nX=series_df[['sd_anglez_1','sd_enmo_1','anglez','m_anglez_2','m_enmo_2','enmo','cluster']]\ny=series_df[['sleep']]\nX=scale(X)\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Scaling']=dt.now()-tnow\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:26:24.402070Z","iopub.execute_input":"2023-12-09T10:26:24.402826Z","iopub.status.idle":"2023-12-09T10:33:26.429353Z","shell.execute_reply.started":"2023-12-09T10:26:24.402787Z","shell.execute_reply":"2023-12-09T10:33:26.427796Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Importing Training Datasets\nDatasets Imported...\nTime Taken:  0:01:12.574773\nMemory Used GB:  2.737819992005825\n______________________________________\nMerging the training datasets...\nDatasets Merged...\nTime Taken:  0:02:11.070029\nMemory Used:  10.486951594240963\n______________________________________\nRemoving the periods of Inactivity...\nshape before application:  (127946340, 7)\nshape after application:  (111766109, 8)\nshape after completion:  (111766109, 7)\nremoved \n______________________________________\nCreating Windows each size:  720\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6928/6928 [00:16<00:00, 415.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Memory Used:  1.0660394178703427\nWindows formed...\nTime Taken:  0:00:24.805480\n______________________________________\nAdding columns to account for deviation in enmo and anglez 1 min rolling...\nanglez rolling std 12\nanglez rolling std 2\nenmo rolling std 12\nenmo rolling mean 24\nanglez rolling mean 24\nenmo rolling std 2\nNans in sd_emno_1:  2959\nenmo rolling mean 2\nanglez rolling mean 2\nNans in sd_emno_1:  269\nNans after removal:  0\nMemory Used GB:  1.268339148722589\nStd columns added...\nTime Taken:  0:01:04.363566\n______________________________________\nClustering the data based on enmo and anglez...\nMemory Used GB:  0.5817822804674506\nTime Taken:  0:01:40.868780\nAdded clusters...\n______________________________________\nMemory Used GB:  0.9498797813430429\nTime Taken:  0:01:42.322946\n","output_type":"stream"}]},{"cell_type":"code","source":"stats.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:33:26.431046Z","iopub.execute_input":"2023-12-09T10:33:26.431420Z","iopub.status.idle":"2023-12-09T10:33:26.449475Z","shell.execute_reply.started":"2023-12-09T10:33:26.431388Z","shell.execute_reply":"2023-12-09T10:33:26.448075Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"     function  pandas_mem pandas_duration  polars_mem  polars_duration\n0     Reading    2.737820  0:01:12.574996         0.0              0.0\n1   Windowing    1.066039  0:00:24.805578         0.0              0.0\n2     Rolling    1.268339  0:01:04.363659         0.0              0.0\n3     Merging   10.486952  0:02:11.070406         0.0              0.0\n4  Clustering    0.581782  0:01:40.868976         0.0              0.0\n5     Scaling    0.949880  0:01:42.323198         0.0              0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>function</th>\n      <th>pandas_mem</th>\n      <th>pandas_duration</th>\n      <th>polars_mem</th>\n      <th>polars_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Reading</td>\n      <td>2.737820</td>\n      <td>0:01:12.574996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Windowing</td>\n      <td>1.066039</td>\n      <td>0:00:24.805578</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rolling</td>\n      <td>1.268339</td>\n      <td>0:01:04.363659</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Merging</td>\n      <td>10.486952</td>\n      <td>0:02:11.070406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clustering</td>\n      <td>0.581782</td>\n      <td>0:01:40.868976</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Scaling</td>\n      <td>0.949880</td>\n      <td>0:01:42.323198</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stats['pandas_duration']=stats['pandas_duration'].dt.total_seconds()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:47:23.738980Z","iopub.execute_input":"2023-12-09T10:47:23.740749Z","iopub.status.idle":"2023-12-09T10:47:23.751110Z","shell.execute_reply.started":"2023-12-09T10:47:23.740687Z","shell.execute_reply":"2023-12-09T10:47:23.748859Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"stats","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:47:56.882806Z","iopub.execute_input":"2023-12-09T10:47:56.883313Z","iopub.status.idle":"2023-12-09T10:47:56.901421Z","shell.execute_reply.started":"2023-12-09T10:47:56.883276Z","shell.execute_reply":"2023-12-09T10:47:56.900095Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"     function  pandas_mem  pandas_duration  polars_mem  polars_duration\n0     Reading    2.737820        72.574996         0.0              0.0\n1   Windowing    1.066039        24.805578         0.0              0.0\n2     Rolling    1.268339        64.363659         0.0              0.0\n3     Merging   10.486952       131.070406         0.0              0.0\n4  Clustering    0.581782       100.868976         0.0              0.0\n5     Scaling    0.949880       102.323198         0.0              0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>function</th>\n      <th>pandas_mem</th>\n      <th>pandas_duration</th>\n      <th>polars_mem</th>\n      <th>polars_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Reading</td>\n      <td>2.737820</td>\n      <td>72.574996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Windowing</td>\n      <td>1.066039</td>\n      <td>24.805578</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rolling</td>\n      <td>1.268339</td>\n      <td>64.363659</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Merging</td>\n      <td>10.486952</td>\n      <td>131.070406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clustering</td>\n      <td>0.581782</td>\n      <td>100.868976</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Scaling</td>\n      <td>0.949880</td>\n      <td>102.323198</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Polars Functions","metadata":{}},{"cell_type":"code","source":"def window_polars(df, win_size):\n    tracemalloc.stop()\n    ind=df.index[df['event'].isna()==False]\n    c=0\n    df['window']=pl.nan\n    for i in tqdm(ind):\n        a=i-win_size\n        b=i+win_size\n        df['window'].loc[a:i]=int(c)\n        c=c+1\n        df['window'].loc[i:b]=int(c)\n        c=c+1\n    df['window'].dropna(inplace=True)\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    stats['pandas_mem'][stats['function']=='Clustering']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\n    tracemalloc.stop()\n    return df[df['window'].is_null()==False]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T10:48:15.116530Z","iopub.execute_input":"2023-12-09T10:48:15.117095Z","iopub.status.idle":"2023-12-09T10:48:15.126654Z","shell.execute_reply.started":"2023-12-09T10:48:15.117054Z","shell.execute_reply":"2023-12-09T10:48:15.125123Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def clustering(df):\n    tracemalloc.start()\n    global stats\n    from sklearn.cluster import KMeans\n    from sklearn.preprocessing import StandardScaler    \n    X=df[['anglez','enmo']]\n#Scalling the data\n    scaler=StandardScaler()\n    X_scaled=scaler.fit_transform(X)\n#perform clustering\n    model=KMeans(n_clusters=4,algorithm=\"elkan\" )\n    model.fit(X_scaled)\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    stats['pandas_mem'][stats['function']=='Clustering']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\n    tracemalloc.stop()\n    return model.labels_","metadata":{},"execution_count":null,"outputs":[]}]}