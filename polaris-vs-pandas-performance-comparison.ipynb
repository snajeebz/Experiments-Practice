{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Polaris vs Pandas](https://www.kaggle.com/najeebz/polaris-vs-pandas-performance-comparison)\n## Dataset: [Child Mind Institute - Detect Sleep States](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/overview)\n_______________________________________________________________________ \n# Author Details:\n- Name: Najeeb Haider Zaidi\n- Email: zaidi.nh@gmail.com\n- Profiles: [Github](https://github.com/snajeebz)  [LinkedIn](https://www.linkedin.com/in/najeebz) [Kaggle](https://www.kaggle.com/najeebz)\n- Copyrights 2023-2024 (c) are reserved only by the author: Najeeb Haider Zaidi\n- Opensource; anyone can copy use and reuse the code and results.\n________________________________________________________________________\n# Attributions:\nThe Dataset has been provided by Child Mind Institute. in [Kaggle Competition](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/overview).\n________________________________________________________________________\n\n# Objective:\n\n> We need to compare Pandas and Polaris, we will run different operations through Pandas and Polaris and generate a comparison report of the both at the end.","metadata":{}},{"cell_type":"markdown","source":"# Installing and Importing and Initializing Libraries.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\nimport polars as pl\nfrom datetime import datetime as dt\nfrom tqdm import tqdm\nimport tracemalloc\ntqdm.pandas()\npd.set_option('display.max_row', 500)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_colwidth', None)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-09T09:48:43.087762Z","iopub.execute_input":"2023-12-09T09:48:43.088225Z","iopub.status.idle":"2023-12-09T09:48:43.819314Z","shell.execute_reply.started":"2023-12-09T09:48:43.088191Z","shell.execute_reply":"2023-12-09T09:48:43.817757Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Windowing the training data\n### As the target is to detect an event, \n### So, extracting timesteps before and after the events. ","metadata":{}},{"cell_type":"code","source":"def window(df, win_size):\n    tracemalloc.start()\n\n    ind=df.index[df['event'].isna()==False]\n    c=0\n    df['window']=np.nan\n    for i in tqdm(ind):\n        a=i-win_size\n        b=i+win_size\n        df['window'].loc[a:i]=int(c)\n        c=c+1\n        df['window'].loc[i:b]=int(c)\n        c=c+1\n    df['window'].dropna(inplace=True)\n    print( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    tracemalloc.stop()\n    return df[df['window'].isna()==False]\n\n\ndef window_polars(df, win_size):\n    ind=df.index[df['event'].isna()==False]\n    c=0\n    df['window']=np.nan\n    for i in tqdm(ind):\n        a=i-win_size\n        b=i+win_size\n        df['window'].loc[a:i]=int(c)\n        c=c+1\n        df['window'].loc[i:b]=int(c)\n        c=c+1\n    df['window'].dropna(inplace=True)\n\n    return df[df['window'].isna()==False]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.822357Z","iopub.execute_input":"2023-12-09T09:48:43.823235Z","iopub.status.idle":"2023-12-09T09:48:43.837530Z","shell.execute_reply.started":"2023-12-09T09:48:43.823176Z","shell.execute_reply":"2023-12-09T09:48:43.836094Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Removing the steps where change in anglez is insignificant and enmo is zero (device is supposed not to be worn)","metadata":{}},{"cell_type":"code","source":"def inactive_periods(df):\n    print(\"shape before application: \",df.shape)\n    df['diff_anglez']=df['anglez'].diff()\n    df=df[(df['enmo']!=0.0) | (df['diff_anglez']!=0.0)]\n    print(\"shape after application: \",df.shape)\n    df.drop('diff_anglez', inplace=True, axis=1)\n    print(\"shape after completion: \",df.shape)\n    print(\"removed \")\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.839217Z","iopub.execute_input":"2023-12-09T09:48:43.839717Z","iopub.status.idle":"2023-12-09T09:48:43.852654Z","shell.execute_reply.started":"2023-12-09T09:48:43.839673Z","shell.execute_reply":"2023-12-09T09:48:43.851042Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Clustering the Enmo and Anglez","metadata":{}},{"cell_type":"code","source":"def clustering(df):\n    tracemalloc.start()\n\n    from sklearn.cluster import KMeans\n    from sklearn.preprocessing import StandardScaler    \n    X=df[['anglez','enmo']]\n#Scalling the data\n    scaler=StandardScaler()\n    X_scaled=scaler.fit_transform(X)\n#perform clustering\n    model=KMeans(n_clusters=4,algorithm=\"elkan\" )\n    model.fit(X_scaled)\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    tracemalloc.stop()\n    return model.labels_\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.856640Z","iopub.execute_input":"2023-12-09T09:48:43.858296Z","iopub.status.idle":"2023-12-09T09:48:43.869882Z","shell.execute_reply.started":"2023-12-09T09:48:43.858231Z","shell.execute_reply":"2023-12-09T09:48:43.868481Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Adding Rolling Standard Deviations\n\n- As per observation enmo and anglez varies frequently and more than normal for few timesteps before and after the event.\n- In order to consider the variations into the modelling, using the method.","metadata":{}},{"cell_type":"code","source":" def rollingstd(series_df):\n    tracemalloc.start()\n  # Creating columns with nans\n    series_df['sd_enmo_1']=np.nan    # 1 min rolling std: enmo\n    series_df['sd_anglez_1']=np.nan  # 1 min rolling std: anglez\n    series_df['m_enmo_2']=np.nan     # 2 min rolling mean: enmo\n    series_df['m_anglez_2']=np.nan   # 2 min rolling std: anglez \n    print('anglez rolling std 12')\n    series_df['sd_anglez_1'] = (series_df.groupby('series_id')['anglez']\n                      .rolling(12)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling std 2')\n    series_df['sd_anglez_1'][series_df['sd_anglez_1'].isna()==True] = (series_df.groupby('series_id')['anglez']\n                      .rolling(2)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling std 12')\n    series_df['sd_enmo_1'] = (series_df.groupby('series_id')['enmo']\n                      .rolling(12)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling mean 24')\n    series_df['m_enmo_2'] = (series_df.groupby('series_id')['enmo']\n                      .rolling(24)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling mean 24')\n    series_df['m_anglez_2'] = (series_df.groupby('series_id')['anglez']\n                      .rolling(24)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling std 2')\n    print('Nans in sd_emno_1: ',series_df['sd_enmo_1'].isnull().sum())\n    series_df['sd_enmo_1'][series_df['sd_enmo_1'].isna()==True] = (series_df.groupby('series_id')['enmo']\n                      .rolling(2)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling mean 2')\n    series_df['m_enmo_2'][series_df['m_enmo_2'].isna()==True] = (series_df.groupby('series_id')['enmo']\n                      .rolling(2)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling mean 2')\n    series_df['m_anglez_2'][series_df['m_anglez_2'].isna()==True] = (series_df.groupby('series_id')['anglez']\n                      .rolling(2)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n#Series wise rolling std and mean\n# filling rest of nans\n    print('Nans in sd_emno_1: ',series_df['sd_enmo_1'].isnull().sum())\n    series_df['sd_enmo_1'].fillna(0.0, inplace=True)\n    series_df['sd_anglez_1'].fillna(0.0, inplace=True)\n    series_df['m_enmo_2'].fillna(0.0, inplace=True)\n    series_df['m_anglez_2'].fillna(0.0, inplace=True)\n    print('Nans after removal: ',series_df['sd_enmo_1'].isnull().sum())\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    tracemalloc.stop()\n    return(series_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.872143Z","iopub.execute_input":"2023-12-09T09:48:43.872548Z","iopub.status.idle":"2023-12-09T09:48:43.900497Z","shell.execute_reply.started":"2023-12-09T09:48:43.872518Z","shell.execute_reply":"2023-12-09T09:48:43.898148Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Scaling the data","metadata":{}},{"cell_type":"code","source":"def scale(X):\n    tracemalloc.start()\n    from sklearn import preprocessing\n    scaler=preprocessing.StandardScaler().fit(X)\n    print( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n    tracemalloc.stop()\n    return (scaler.transform(X))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.902557Z","iopub.execute_input":"2023-12-09T09:48:43.903046Z","iopub.status.idle":"2023-12-09T09:48:43.920989Z","shell.execute_reply.started":"2023-12-09T09:48:43.903014Z","shell.execute_reply":"2023-12-09T09:48:43.919043Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"a=dt.now()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.924449Z","iopub.execute_input":"2023-12-09T09:48:43.925404Z","iopub.status.idle":"2023-12-09T09:48:43.936287Z","shell.execute_reply.started":"2023-12-09T09:48:43.925344Z","shell.execute_reply":"2023-12-09T09:48:43.934999Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"b=dt.now()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.938784Z","iopub.execute_input":"2023-12-09T09:48:43.940141Z","iopub.status.idle":"2023-12-09T09:48:43.952071Z","shell.execute_reply.started":"2023-12-09T09:48:43.940072Z","shell.execute_reply":"2023-12-09T09:48:43.950886Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dict = {'function':['Reading','Windowing', 'Rolling', 'Merging', 'Clustering','Scaling'],\n        'pandas_mem':[0.0,0,0,0,0,0.0],\n        'pandas_duration':[0.0,0,0,0,0,0.0],\n        'polars_mem': [0.0,0,0,0,0,0.0],\n        'polars_duration':[0.0,0,0,0,0,0.0]\n       }\n\nstats = pd.DataFrame(dict)\nstats\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:43.953827Z","iopub.execute_input":"2023-12-09T09:48:43.955581Z","iopub.status.idle":"2023-12-09T09:48:44.000500Z","shell.execute_reply.started":"2023-12-09T09:48:43.955511Z","shell.execute_reply":"2023-12-09T09:48:43.998985Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"     function  pandas_mem  pandas_duration  polars_mem  polars_duration\n0     Reading         0.0              0.0         0.0              0.0\n1   Windowing         0.0              0.0         0.0              0.0\n2     Rolling         0.0              0.0         0.0              0.0\n3     Merging         0.0              0.0         0.0              0.0\n4  Clustering         0.0              0.0         0.0              0.0\n5     Scaling         0.0              0.0         0.0              0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>function</th>\n      <th>pandas_mem</th>\n      <th>pandas_duration</th>\n      <th>polars_mem</th>\n      <th>polars_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Reading</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Windowing</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rolling</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Merging</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clustering</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Scaling</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Testing Pandas","metadata":{}},{"cell_type":"code","source":"# Importing the datasets\nprint('Importing Training Datasets')\ntnow=dt.now()\ntracemalloc.start()\ndf_series=pd.read_parquet(path=\"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\", engine='auto')\ndf_events=pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\nprint('Datasets Imported...')\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Reading']=dt.now()-tnow\nstats['pandas_mem'][stats['function']=='Reading']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\nprint( 'Memory Used GB: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n\ntracemalloc.stop()\nprint('______________________________________')\n\n# Merging the datasets\nprint('Merging the training datasets...')\ntnow=dt.now()\ntracemalloc.start()\nevents=df_events[['series_id', 'step','event']]\nseries_df=pd.merge(df_series,events,on=[\"step\",\"series_id\"],how='left')\ndf_series=[]\ndf_event=[]\nseries_df['sleep']=np.nan\nseries_df.loc[series_df[\"event\"]==\"onset\", \"sleep\"] = 1\nseries_df.loc[series_df[\"event\"]==\"wakeup\", \"sleep\"] = 0\nseries_df['sleep'].fillna(method='ffill', inplace=True)\nseries_df['sleep'].fillna(value=0, inplace=True)\nprint('Datasets Merged...')\nprint('Time Taken: ',dt.now()-tnow)\nprint( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\nstats['pandas_duration'][stats['function']=='Merging']=dt.now()-tnow\nstats['pandas_mem'][stats['function']=='Merging']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\ntracemalloc.stop()\nprint('______________________________________')\n\n# Removing the periods of inactivity\nprint('Removing the periods of Inactivity...')\nseries_df=inactive_periods(series_df)\nprint('______________________________________')\ntracemalloc.start()\n# Forming Windows\nwin_size=720  #60mins\ntnow=dt.now()\nprint('Creating Windows each size: ',win_size)\n# series_df=window(series_df,win_size)\nprint('Windows formed...')\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Windowing']=dt.now()-tnow\nstats['pandas_mem'][stats['function']=='Windowing']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\nprint( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\ntracemalloc.stop()\n\nprint('______________________________________')\n\n# Adding the columns of Standard Deviation (1 min)\ntnow=dt.now()\ntracemalloc.start()\nprint('Adding columns to account for deviation in enmo and anglez 1 min rolling...')\nseries_df=rollingstd(series_df)\nseries_df['sd_anglez_1']=pd.to_numeric(series_df['sd_anglez_1'])\nseries_df['sd_enmo_1']=pd.to_numeric(series_df['sd_enmo_1'])\nseries_df['m_anglez_2']=pd.to_numeric(series_df['m_anglez_2'])\nseries_df['m_enmo_2']=pd.to_numeric(series_df['m_enmo_2'])\nprint('Std columns added...')\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Rolling']=dt.now()-tnow\nstats['pandas_mem'][stats['function']=='Rolling']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\nprint( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\ntracemalloc.stop()\nprint('______________________________________')\n\n# Clustering the Data\ntnow=dt.now()\ntracemalloc.start()\nprint('Clustering the data based on enmo and anglez...')\nseries_df['cluster']=(clustering(series_df)+1)/4\nprint('Time Taken: ',dt.now()-tnow)\nstats['pandas_duration'][stats['function']=='Clustering']=dt.now()-tnow\nstats['pandas_mem'][stats['function']=='Clustering']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\nprint( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\ntracemalloc.stop()\nprint('Added clusters...')\nprint('______________________________________')\nstats\n# Creating dataframes for training\n#tracemalloc.start()\n#X=series_df[['sd_anglez_1','sd_enmo_1','anglez','m_anglez_2','m_enmo_2','enmo','cluster']]\n#y=series_df[['sleep']]\n#X=scale(X)\n#print('Time Taken: ',dt.now()-tnow)\n#stats['pandas_duration'][stats['function']=='Clustering']=dt.now()-tnow\n#stats['pandas_mem'][stats['function']=='Clustering']=tracemalloc.get_traced_memory()[1]/1024/1024/1024\n#print( 'Memory Used: ',tracemalloc.get_traced_memory()[1]/1024/1024/1024)\n#tracemalloc.stop()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T09:48:44.005459Z","iopub.execute_input":"2023-12-09T09:48:44.005958Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Importing Training Datasets\n","output_type":"stream"}]},{"cell_type":"code","source":"stats\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}